{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05123f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop_words in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (2018.7.23)\r\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "!pip install stop_words\n",
    "# Define function for tokenize and lemmatizing\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3bb90",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a8b7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The article discuss the dental informatics as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The goal of the Collaboration Spotting project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The article talks about how dental informatics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This journal review points out the articles ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The article talks about dental informatics as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Abstract\n",
       "0           0  The article discuss the dental informatics as ...\n",
       "1           1  The goal of the Collaboration Spotting project...\n",
       "2           2  The article talks about how dental informatics...\n",
       "3           3  This journal review points out the articles ab...\n",
       "4           4  The article talks about dental informatics as ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the header from 'Summary' to 'Abstract'\n",
    "df = pd.read_csv('abstract.csv', index_col = False)\n",
    "df.rename(columns = {'Summary':'Abstract'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26791c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec591ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "\n",
    "#lowercase and removing special characters and commonly occurring words\n",
    "#df['Abstract'] = df['Abstract'].apply(lambda x: \" \".join(x for x in str(x).split() if not x.isdigit() and not x.isspace()))\n",
    "#df['Abstract'] = df['Abstract'].str.replace(r'[^\\w\\s]','')\n",
    "#df['Abstract'] = df['Abstract'].str.replace(r'\\d+', '')\n",
    "#df['Abstract'] = df['Abstract'].str.lower()\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "df['Abstract']= df['Abstract'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091878fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists of abstract and combine list to string\n",
    "\n",
    "# create list of documents\n",
    "abstract_set = [abstract for abstract in df['Abstract']]\n",
    "\n",
    "# Remove new line characters\n",
    "abstract_set = [re.sub(r'\\s+', ' ', sent) for sent in abstract_set]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "abstract_set = [re.sub(\"\\'\", \"\", sent) for sent in abstract_set]\n",
    "\n",
    "# combine list to string \n",
    "abstract_string = ' '.join([(item) for item in abstract_set])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42d2f3",
   "metadata": {},
   "source": [
    "## new dataset with only 'Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c7ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataset with only Titles\n",
    "titles = pd.read_csv('article_info.csv')\n",
    "header = ['Title']\n",
    "titles.to_csv('title.csv', columns = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c315cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('title.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab22b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "\n",
    "#lowercase and removing special characters and commonly occurring words\n",
    "#df1['Title'] = df1['Title'].apply(lambda x: \" \".join(x for x in str(x).split() if not x.isdigit() and not x.isspace()))\n",
    "#df1['Title'] = df1['Title'].str.replace(r'[^\\w\\s]','')\n",
    "#df1['Title'] = df1['Title'].str.replace(r'\\d+', '')\n",
    "#df1['Title'] = df1['Title'].str.lower()\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "df1['Title']= df1['Title'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f3b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists of abstract and combine list to string\n",
    "\n",
    "# create list of documents\n",
    "title_set = [title for title in df1['Title']]\n",
    "\n",
    "# Remove new line characters\n",
    "title_set = [re.sub(r'\\s+', ' ', sent) for sent in title_set]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "title_set = [re.sub(\"\\'\", \"\", sent) for sent in title_set]\n",
    "\n",
    "# combine list to string \n",
    "title_string = ' '.join([(item) for item in title_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8103f8d",
   "metadata": {},
   "source": [
    "# Import required packages for keyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5579ddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading keybert-0.5.0.tar.gz (19 kB)\n",
      "Collecting sentence-transformers>=0.3.8\n",
      "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from keybert) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from keybert) (1.21.2)\n",
      "Collecting rich>=10.4.0\n",
      "  Downloading rich-11.0.0-py3-none-any.whl (215 kB)\n",
      "\u001b[K     |████████████████████████████████| 215 kB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: colorama<0.5.0,>=0.4.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from rich>=10.4.0->keybert) (0.4.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from rich>=10.4.0->keybert) (2.10.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.2->keybert) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22.2->keybert) (2.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (4.11.2)\n",
      "Requirement already satisfied: tokenizers>=0.10.3 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (0.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (1.9.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp38-cp38-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (3.6.5)\n",
      "Requirement already satisfied: sentencepiece in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.96)\n",
      "Requirement already satisfied: huggingface-hub in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers>=0.3.8->keybert) (0.0.17)\n",
      "Requirement already satisfied: typing-extensions in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.10.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.8.3)\n",
      "Requirement already satisfied: filelock in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.3.1)\n",
      "Requirement already satisfied: sacremoses in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.0.46)\n",
      "Requirement already satisfied: requests in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
      "Requirement already satisfied: click in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.3)\n",
      "Requirement already satisfied: six in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.16.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /Users/thiphan/opt/anaconda3/lib/python3.8/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (8.4.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.10.1-cp38-none-macosx_10_9_x86_64.whl (147.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 147.1 MB 47 kB/s  eta 0:00:012\n",
      "\u001b[?25hBuilding wheels for collected packages: keybert, sentence-transformers\n",
      "  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keybert: filename=keybert-0.5.0-py3-none-any.whl size=20491 sha256=65d4d1079cab523263d580c3e653e2390b410cf674ba3807781a0307230e6a27\n",
      "  Stored in directory: /Users/thiphan/Library/Caches/pip/wheels/b2/a2/41/91076fdeb475bad8934810b0148532cace93ae0dbd3d5e1be2\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=649d0f65f7b0e4e18ac417bd55b9c05efd82b3f468494b52ea993b80b0220914\n",
      "  Stored in directory: /Users/thiphan/Library/Caches/pip/wheels/52/19/88/6625593382e23a926740e6fcee0f2df0a0de25766094842a28\n",
      "Successfully built keybert sentence-transformers\n",
      "Installing collected packages: torch, torchvision, commonmark, sentence-transformers, rich, keybert\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.1\n",
      "    Uninstalling torch-1.9.1:\n",
      "      Successfully uninstalled torch-1.9.1\n",
      "Successfully installed commonmark-0.9.1 keybert-0.5.0 rich-11.0.0 sentence-transformers-2.1.0 torch-1.10.1 torchvision-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a5741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1665ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(model = 'distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64276e2",
   "metadata": {},
   "source": [
    "# Abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06f094",
   "metadata": {},
   "source": [
    "## Top 50 keywords (1-grams) from the abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24cb2e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiphan/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dentists', 0.4951),\n",
       " ('bioinformatics', 0.4191),\n",
       " ('dentistry', 0.4807),\n",
       " ('dentist', 0.4555),\n",
       " ('cancer', 0.3524),\n",
       " ('orthodontic', 0.3766),\n",
       " ('dental', 0.3956),\n",
       " ('antibiotics', 0.331),\n",
       " ('radiology', 0.3236),\n",
       " ('diabetes', 0.2828),\n",
       " ('clinics', 0.3189),\n",
       " ('biomedical', 0.3259),\n",
       " ('genomics', 0.3159),\n",
       " ('physicians', 0.3131),\n",
       " ('harvard', 0.2607),\n",
       " ('orthodontist', 0.3557),\n",
       " ('wisconsin', 0.2525),\n",
       " ('proteomics', 0.3062),\n",
       " ('librarian', 0.2605),\n",
       " ('orthognathic', 0.2789),\n",
       " ('clinicians', 0.3142),\n",
       " ('patents', 0.2713),\n",
       " ('therapy', 0.2876),\n",
       " ('videoconferencing', 0.2328),\n",
       " ('researchers', 0.2571),\n",
       " ('medicine', 0.3034),\n",
       " ('pathology', 0.2563),\n",
       " ('exam', 0.2536),\n",
       " ('doctors', 0.3066),\n",
       " ('clinician', 0.311),\n",
       " ('techcnological', 0.2522),\n",
       " ('nurse', 0.2501),\n",
       " ('clinic', 0.2955),\n",
       " ('biomaterials', 0.2832),\n",
       " ('smartphones', 0.1877),\n",
       " ('universities', 0.2361),\n",
       " ('2007', 0.2117),\n",
       " ('tumor', 0.2699),\n",
       " ('faculty', 0.2635),\n",
       " ('radiography', 0.2661),\n",
       " ('1107', 0.2052),\n",
       " ('doctor', 0.2776),\n",
       " ('interviews', 0.2243),\n",
       " ('pcr', 0.2315),\n",
       " ('restorations', 0.2431),\n",
       " ('inforamtics', 0.2369),\n",
       " ('endodontically', 0.2554),\n",
       " ('healthcare', 0.2589),\n",
       " ('academic', 0.2477),\n",
       " ('tomography', 0.2015)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(abstract_string, \n",
    "                          top_n = 50,\n",
    "                          keyphrase_ngram_range=(1, 1),\n",
    "                          use_mmr = True,\n",
    "                          diversity = 0.2,\n",
    "                          stop_words=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d20ca",
   "metadata": {},
   "source": [
    "## Top 50 keywords (2-grams) from the abstracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae5dbfe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiphan/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bioinformatics dental', 0.6829),\n",
       " ('dentistry questionnaire', 0.6347),\n",
       " ('dental research', 0.6441),\n",
       " ('cancer patients', 0.536),\n",
       " ('dentists interview', 0.6036),\n",
       " ('informatics dentistry', 0.6253),\n",
       " ('dentistry years', 0.5956),\n",
       " ('dentistry guide', 0.6176),\n",
       " ('dentistry survey', 0.623),\n",
       " ('dental educators', 0.6057),\n",
       " ('visualization dentists', 0.6005),\n",
       " ('dental biomaterials', 0.6077),\n",
       " ('dental informatics', 0.6077),\n",
       " ('school dentistry', 0.5853),\n",
       " ('bioinformatics courses', 0.5409),\n",
       " ('revolution dental', 0.5493),\n",
       " ('dentistry reusing', 0.5801),\n",
       " ('delivering dental', 0.5818),\n",
       " ('dental radiology', 0.5759),\n",
       " ('clinical dentistry', 0.5854),\n",
       " ('dental practinoers', 0.5885),\n",
       " ('updated dental', 0.5687),\n",
       " ('dental postgraduate', 0.5836),\n",
       " ('dentists learning', 0.5845),\n",
       " ('workflow dental', 0.5839),\n",
       " ('dental academy', 0.5833),\n",
       " ('dental medicine', 0.5866),\n",
       " ('challenges dentists', 0.5658),\n",
       " ('hygienist dentists', 0.5741),\n",
       " ('dental faculty', 0.5865),\n",
       " ('dental inforamtics', 0.5862),\n",
       " ('86 dentists', 0.5458),\n",
       " ('dental students', 0.5838),\n",
       " ('dentists transition', 0.5635),\n",
       " ('informatics dental', 0.5869),\n",
       " ('oral cancer', 0.5258),\n",
       " ('dental education', 0.5755),\n",
       " ('dental informaticians', 0.5836),\n",
       " ('hygienists dental', 0.5768),\n",
       " ('patterns dentists', 0.5631),\n",
       " ('computerization dental', 0.5682),\n",
       " ('examined dentists', 0.5745),\n",
       " ('adoption dental', 0.5459),\n",
       " ('undergraduate dental', 0.5615),\n",
       " ('engineering dental', 0.5662),\n",
       " ('practice dentistry', 0.5657),\n",
       " ('dental tumor', 0.5579),\n",
       " ('dental software', 0.5672),\n",
       " ('physicians dentists', 0.5659),\n",
       " ('students dentists', 0.5623)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with low diversity\n",
    "\n",
    "kw_model.extract_keywords(abstract_string, \n",
    "                          top_n = 50,\n",
    "                          keyphrase_ngram_range=(1, 2),\n",
    "                          use_mmr = True,\n",
    "                          diversity = 0.2,\n",
    "                          stop_words=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b286366",
   "metadata": {},
   "source": [
    "## Top 50 keywords (3-grams) from the abstracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc99938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiphan/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dental informatics research', 0.7422),\n",
       " ('revolution bioinformatics dental', 0.7283),\n",
       " ('updated dental providers', 0.7065),\n",
       " ('education continuing dental', 0.7024),\n",
       " ('dental research students', 0.7137),\n",
       " ('dental informaticians researchers', 0.7228),\n",
       " ('bioinformatics dental informatics', 0.7271),\n",
       " ('dental education explore', 0.7101),\n",
       " ('dentistry questionnaire survey', 0.6949),\n",
       " ('techcnological changes dentistry', 0.6869),\n",
       " ('dental informatics evolving', 0.7046),\n",
       " ('research tools dentistry', 0.6969),\n",
       " ('dental clinical research', 0.7143),\n",
       " ('development dental students', 0.6998),\n",
       " ('developing dental informatics', 0.7081),\n",
       " ('dentistry reusing research', 0.6837),\n",
       " ('oral cancer genomics', 0.6438),\n",
       " ('dental informatics biomedical', 0.7051),\n",
       " ('dentists interview transcripts', 0.6622),\n",
       " ('engineering dental research', 0.6981),\n",
       " ('dental research summarizing', 0.7014),\n",
       " ('healthcare dental research', 0.7005),\n",
       " ('technologies adoption dental', 0.6793),\n",
       " ('dental informatics applications', 0.7024),\n",
       " ('discuss dental informatics', 0.6882),\n",
       " ('dental informatics developing', 0.7017),\n",
       " ('practice dentistry survey', 0.6874),\n",
       " ('informatics developing dental', 0.6985),\n",
       " ('dental informatics emerging', 0.6891),\n",
       " ('implement informatics dentistry', 0.6782),\n",
       " ('clinical dentistry questionnaire', 0.6866),\n",
       " ('dental informatics online', 0.6663),\n",
       " ('dental pbrn studies', 0.6775),\n",
       " ('developed dental faculty', 0.671),\n",
       " ('made dental biomaterials', 0.6661),\n",
       " ('informatics dental education', 0.6796),\n",
       " ('radiography dentistry guide', 0.6545),\n",
       " ('dental informatics university', 0.6789),\n",
       " ('study examined dentists', 0.6663),\n",
       " ('guide dental practinoers', 0.6618),\n",
       " ('dentistry survey questionnaire', 0.6887),\n",
       " ('standards dental informatics', 0.6805),\n",
       " ('bioinformatics dental', 0.6829),\n",
       " ('dental medicine pilot', 0.651),\n",
       " ('dental practice data', 0.6737),\n",
       " ('explored dental clinical', 0.6738),\n",
       " ('interpreting dental tumor', 0.6596),\n",
       " ('program clinical dentistry', 0.6727),\n",
       " ('undergraduate dental education', 0.652),\n",
       " ('continuing dental education', 0.6824)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(abstract_string, \n",
    "                          top_n = 50,\n",
    "                          keyphrase_ngram_range=(1, 3),\n",
    "                          use_mmr = True,\n",
    "                          diversity = 0.2,\n",
    "                          stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f90b04c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiphan/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bioinformatics dental', 0.6829),\n",
       " ('latest initiatives', 0.2287),\n",
       " ('500 patients', 0.1676),\n",
       " ('smoking history', 0.2985),\n",
       " ('diabetes increased', 0.2853),\n",
       " ('university texas', 0.2336),\n",
       " ('cancer patients', 0.536),\n",
       " ('102 provoders', 0.2775),\n",
       " ('school administrators', 0.2444),\n",
       " ('broadband technologies', 0.2557),\n",
       " ('pilot testing', 0.3068),\n",
       " ('clinics chinese', 0.2848),\n",
       " ('trends iowa', 0.3084),\n",
       " ('clinic july', 0.3333),\n",
       " ('canal therapy', 0.4501),\n",
       " ('statistics lessons', 0.3123),\n",
       " ('revolution bioinformatics', 0.4779),\n",
       " ('researchers successfully', 0.2416),\n",
       " ('harvard school', 0.3148),\n",
       " ('jordanian students', 0.2413),\n",
       " ('completed orthodontic', 0.4358),\n",
       " ('twenty dental', 0.3019),\n",
       " ('health data', 0.3356),\n",
       " ('forest naïve', -0.0131),\n",
       " ('2017 data', 0.2536),\n",
       " ('years interviewing', 0.3386),\n",
       " ('research oral', 0.4341),\n",
       " ('smartphones positive', 0.1634),\n",
       " ('genomic studies', 0.4186),\n",
       " ('different dentists', 0.4403),\n",
       " ('scandinavian practitioner', 0.1798),\n",
       " ('mining methods', 0.2144),\n",
       " ('using sparql', 0.3035),\n",
       " ('fluoride varnish', 0.3337),\n",
       " ('vendors funding', 0.2392),\n",
       " ('dentists germany', 0.4566),\n",
       " ('temporomandibular disorders', 0.2123),\n",
       " ('professionals turkey', 0.2646),\n",
       " ('system xp', 0.1992),\n",
       " ('1626 patients', 0.3033),\n",
       " ('prior dental', 0.3452),\n",
       " ('computerized tomography', 0.3188),\n",
       " ('dentistry better', 0.3835),\n",
       " ('71 patients', 0.2126),\n",
       " ('explain architecture', 0.2995),\n",
       " ('second semester', 0.236),\n",
       " ('private universities', 0.1961),\n",
       " ('school 2009', 0.2577),\n",
       " ('technology researchers', 0.3997),\n",
       " ('digital radiography', 0.3224)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with higher diversity\n",
    "\n",
    "kw_model.extract_keywords(abstract_string, \n",
    "                          top_n = 50,\n",
    "                          keyphrase_ngram_range=(1, 2),\n",
    "                          use_mmr = True,\n",
    "                          diversity = 0.7,\n",
    "                          stop_words=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3453ee0",
   "metadata": {},
   "source": [
    "# Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfc200f",
   "metadata": {},
   "source": [
    "## Top 50 keywords (1-gram) from the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0231261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiphan/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dentistry', 0.4966),\n",
       " ('bioinformatics', 0.4207),\n",
       " ('dentists', 0.4747),\n",
       " ('dentist', 0.4431),\n",
       " ('dental', 0.3994),\n",
       " ('medicine', 0.3559),\n",
       " ('cancer', 0.3197),\n",
       " ('clinics', 0.35),\n",
       " ('orthodontic', 0.3427),\n",
       " ('biomedical', 0.3325),\n",
       " ('genomics', 0.3213),\n",
       " ('diabetes', 0.2778),\n",
       " ('clinic', 0.331),\n",
       " ('healthcare', 0.3178),\n",
       " ('biomaterials', 0.2984),\n",
       " ('pathology', 0.2553),\n",
       " ('innovation', 0.2509),\n",
       " ('therapy', 0.2641),\n",
       " ('radiography', 0.2299),\n",
       " ('academics', 0.2208),\n",
       " ('informatics', 0.2403),\n",
       " ('digidontics', 0.2299),\n",
       " ('medical', 0.2799),\n",
       " ('dentofacial', 0.2274),\n",
       " ('tumor', 0.2516),\n",
       " ('myanmar', 0.1738),\n",
       " ('hospital', 0.259),\n",
       " ('saudi', 0.1729),\n",
       " ('broadband', 0.177),\n",
       " ('engineering', 0.1972),\n",
       " ('chinas', 0.1454),\n",
       " ('decades', 0.1456),\n",
       " ('pubmed', 0.1807),\n",
       " ('universities', 0.1967),\n",
       " ('hygienists', 0.1893),\n",
       " ('epidemiology', 0.1934),\n",
       " ('online', 0.1723),\n",
       " ('mapping', 0.1834),\n",
       " ('legal', 0.1622),\n",
       " ('clinical', 0.2017),\n",
       " ('postgraduates', 0.1755),\n",
       " ('jordan', 0.1697),\n",
       " ('software', 0.1749),\n",
       " ('medically', 0.2169),\n",
       " ('restorative', 0.1531),\n",
       " ('faculty', 0.1872),\n",
       " ('smartconsent', 0.1709),\n",
       " ('diagnostic', 0.1821),\n",
       " ('ontology', 0.1568),\n",
       " ('2009', 0.1282)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(title_string, \n",
    "                          top_n = 50,\n",
    "                          keyphrase_ngram_range=(1, 1), \n",
    "                          use_mmr = True,\n",
    "                          diversity = 0.2,\n",
    "                          stop_words=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97658e64",
   "metadata": {},
   "source": [
    "## Top 50 keywords (2-grams) from the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "554d5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiphan/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('innovation dental', 0.7059),\n",
       " ('medicine informatics', 0.594),\n",
       " ('genomics dental', 0.6494),\n",
       " ('revolution dental', 0.6286),\n",
       " ('dental informatics', 0.6256),\n",
       " ('computerization dentistry', 0.5866),\n",
       " ('clinical dentistry', 0.5965),\n",
       " ('dental research', 0.6064),\n",
       " ('dentists ready', 0.5718),\n",
       " ('technology dental', 0.5883),\n",
       " ('research dental', 0.6011),\n",
       " ('comprehensive dental', 0.5764),\n",
       " ('dentistry course', 0.5907),\n",
       " ('improving dental', 0.5588),\n",
       " ('exploring dental', 0.5845),\n",
       " ('dental radiography', 0.5686),\n",
       " ('dental postgraduates', 0.5815),\n",
       " ('research dentist', 0.5811),\n",
       " ('cornerstone dental', 0.5614),\n",
       " ('dental education', 0.5799),\n",
       " ('repurposing dental', 0.5706),\n",
       " ('oral genomics', 0.5494),\n",
       " ('dental researchers', 0.5826),\n",
       " ('dentists clinical', 0.5704),\n",
       " ('online dental', 0.5426),\n",
       " ('data dentistry', 0.5632),\n",
       " ('evolution dental', 0.5507),\n",
       " ('medical dental', 0.5615),\n",
       " ('training dental', 0.5674),\n",
       " ('dental school', 0.5686),\n",
       " ('dental software', 0.5651),\n",
       " ('technologies dental', 0.5777),\n",
       " ('promote dental', 0.5468),\n",
       " ('scenario dentistry', 0.5623),\n",
       " ('cancer patients', 0.4721),\n",
       " ('restorative dentistry', 0.5387),\n",
       " ('hygienists dentists', 0.5629),\n",
       " ('dental hygienists', 0.5529),\n",
       " ('dental diagnostic', 0.5532),\n",
       " ('dental students', 0.5578),\n",
       " ('implementing dental', 0.5522),\n",
       " ('emerging biomedical', 0.4922),\n",
       " ('ict dentistry', 0.5434),\n",
       " ('dentistry information', 0.5561),\n",
       " ('learning healthcare', 0.5113),\n",
       " ('sciences dental', 0.5522),\n",
       " ('dental tumor', 0.5367),\n",
       " ('based dentistry', 0.5449),\n",
       " ('course bioinformatics', 0.4875),\n",
       " ('testing dental', 0.5478)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(title_string, \n",
    "                          top_n = 50,\n",
    "                          keyphrase_ngram_range=(1, 2), \n",
    "                          use_mmr = True,\n",
    "                          diversity = 0.2,\n",
    "                          stop_words=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed758a0",
   "metadata": {},
   "source": [
    "## Top 50 keywords (3-grams) from the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea4b2496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiphan/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('informatics innovation dental', 0.8034),\n",
       " ('revolution dental education', 0.7421),\n",
       " ('evolution dental informatics', 0.7684),\n",
       " ('genomics dental informatics', 0.7605),\n",
       " ('innovation dental care', 0.7683),\n",
       " ('dental informatics emerging', 0.7453),\n",
       " ('dental informatics cornerstone', 0.7352),\n",
       " ('improving dental research', 0.7172),\n",
       " ('dental researchers informatics', 0.7316),\n",
       " ('emergence dental informatics', 0.7285),\n",
       " ('informatics cornerstone dental', 0.7343),\n",
       " ('informatics improving dental', 0.7231),\n",
       " ('dental informatics online', 0.6995),\n",
       " ('information revolution dental', 0.7126),\n",
       " ('informatics training dental', 0.71),\n",
       " ('dental informatics clinical', 0.7137),\n",
       " ('oral medicine informatics', 0.6803),\n",
       " ('progress dental informatics', 0.7068),\n",
       " ('innovation dental', 0.7059),\n",
       " ('frontier dental informatics', 0.696),\n",
       " ('technology dental education', 0.685),\n",
       " ('dental data integration', 0.6883),\n",
       " ('clinical dentistry pilot', 0.6509),\n",
       " ('dental informatics saudi', 0.6869),\n",
       " ('dental informatics major', 0.6878),\n",
       " ('informatics research dentist', 0.6792),\n",
       " ('informatics emerging biomedical', 0.6235),\n",
       " ('dental practice informatics', 0.6913),\n",
       " ('overview dental informatics', 0.6888),\n",
       " ('visionary scenario dentistry', 0.6693),\n",
       " ('cornerstone dental practice', 0.6808),\n",
       " ('clinical research dental', 0.6807),\n",
       " ('dental students informatics', 0.6857),\n",
       " ('dental education digidontics', 0.675),\n",
       " ('dental research education', 0.6779),\n",
       " ('promote dental students', 0.6602),\n",
       " ('technologies dental radiography', 0.652),\n",
       " ('exploring dental providers', 0.6573),\n",
       " ('setting dental informatics', 0.6825),\n",
       " ('sciences dental informatics', 0.6819),\n",
       " ('healthcare quality dental', 0.6533),\n",
       " ('oral genomics dental', 0.6691),\n",
       " ('computerization restorative dentistry', 0.6567),\n",
       " ('repurposing dental virtual', 0.651),\n",
       " ('digital challenge dental', 0.6487),\n",
       " ('challenges dental informatics', 0.6638),\n",
       " ('interpreting dental tumor', 0.6474),\n",
       " ('research dental restorative', 0.6599),\n",
       " ('advancing oral medicine', 0.6393),\n",
       " ('informatics discipline dental', 0.6723)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(title_string, \n",
    "                          top_n = 50,\n",
    "                          keyphrase_ngram_range=(1, 3), \n",
    "                          use_mmr = True,\n",
    "                          diversity = 0.2,\n",
    "                          stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0433dcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874fc2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87a646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db457387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37edb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
